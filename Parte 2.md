# Parte seconda
## 2.1 Introduzione
Il recente sviluppo delle tecnologie digitali, in particolar modo di internet, ha modificato profondamente le consuetudini sociali, a tal punto da divenire un aspetto fondamentale per l’accesso ai servizi, per l’acquisizione di competenze e per le relazioni interpersonali. Infatti la velocità di trasmissione delle informazioni e la sua possibilità di renderle immediatamente fruibili, anche in zone geograficamente remote, ha portato alla digitalizzazione di moltissime procedure e servizi ai cittadini, segnando un trend in continua crescita. Si è di fronte a quella che storicamente viene considerata la Terza Rivoluzione Industriale[^eremy-Rifki-p329], appunto per sottolinearne la portata innovativa a livello di modello comunicativo, linguaggio interpersonale, relazioni e  ambito lavorativo. Si è assistito negli ultimi decenni allo sviluppo della Rete da strumento di consultazione per l'acquisizione di informazioni, a spazio interattivo promotore di legami e relazioni tra persone e risorse.
Questo stesso sviluppo è stato promotore della diffusione a livello di massa di strumenti tecnologici che prima erano riservati ad ambienti tecnici o lavorativi, promuovendone l’applicazione in tutti i campi e accompagnando un vasto processo di ricerca tecnologica, che ha permesso la drastica riduzione dei costi degli hardware di supporto a fronte del loro continuo aumento di prestazioni e capacità. Nell’arco di pochi decenni dalla nascita della rete, si può facilmente affermare che essa sia diventata un aspetto imprescindibile della vita sociale ed economica di ciascun individuo e della sua realizzazione personale come cittadino.
In particolare, scrive Valentina Arnato nel suo articolo “Accessibilità e usabilità: metodologie di inclusione sociale”: 
> I digital media... sono divenuti spazi di fruizione delle informazioni, così come spazi alternativi alla realtà quotidiana, per la fruizione dei più svariati servizi. Il loro avvento ha ridefinito i concetti di spazio e tempo e di riflesso l’essenza stessa dell’individuo-cittadino: gli ambienti digitali, oltre a ridurre le distanza fisiche e comunicative, generano relazioni che non sono più solo fondate sul rapporto face to face.
[^digital-devide-definizione]

Questa innovazione è nata dapprima nei paesi occidentali più sviluppati per poi rapidamente diffondersi, portando nel breve a confrontarsi con il fenomeno cosiddetto di “digital divide”. [^digital-devide-definizione] Con questo termine, a partire dagli anni Novanta, ci si riferisce al divario socio-culturale tra chi ha completo ed adeguato accesso alle tecnologie digitali e chi, invece, ne è parzialmente o totalmente escluso, generando una disparità nella possibilità di acquisire risorse e competenze indispensabili. Il termine è usato a livello mondiale sia per evidenziare le differenze economico-politiche delle aree che non usufruiscono delle tecnologie informatiche, sia a livello locale per determinate fasce di popolazione. 
Per molte tipologie di disabiliità si aggiungeva un altro problema, l'impossibilità di accedere autonomamente alle risorse di queste tecnologie ed anche ai servizi che venivano erogati per loro tramite. È in questo frangente che si sono sviluppate le prime iniziative legislative da parte dei Governi, dirette ad attuare la parità di accesso alle tecnologie, con l’obbiettivo di colmare tale divario e sviluppare un sistema sociale più equilibrato. Questo processo è sempre più necessario perché, se un tempo la fruizione del digital web prevedeva il solo l'accesso alle informazioni, ora sono sempre più numerosi i servizi e le procedure che prevedono l’accesso esclusivamente via web. [^accessibilita-usabilita-rivista] 
**(vedi se già citato…)** 

## 2.2 Concetto di accessibilità e di usabilità
Oggi vi è la necessità di portare i programmi a livello di tutti (per difficoltà generiche, disabilità specifiche, ma anche quelle insorte tardivamente) perchè sono sempre più nel quotidiano.
naturalmente le disabilità specifiche bisognano di appositi adattamenti.

la democrazia ha portato a un dibattito sul reale significato di uguaglianza / diversità, che si è sviluppato a partire
dall'estensione a tutti del diritto di voto (il riconoscimento cioè che tuttti sono uguali( a considerazioni più "alte".
non a caso gli 11 enunciati della legge stanca prendono le mosse dall'articolo 3 della Costituzione Italiana.

#### cosa deve garantire la società?
Di cosa la società si deve fare carico?
per approfondire questo argomento citare la legge sull'integrazione degli anni '70, che poi, nel 1992 è diventata la legge 104).

Anche a livello internazionale si assiste a affini tipologie di dibattiti, che hanno portato anche  alttrove alla formulazione di leggi che sostanzialmente affermano gli stessi principi ma ciò dimostra come l'attenzione al problema sia sempre maggiore.

(elenchi normative- mondo/europa/italia - già scritti nel doc).

alla profondità del dibattito in questi anni, la pratica fatica a corrispondere.

è interesante sottolineare la diversità del significato di accessibilità e usabilità (già nel doc).
Attuazione di questi principi nelle moderne tecnologie (già abbozzato in doc 2.4.1)
Conclusione: Se questi accorgimenti vengono tralasciati si trascurano grandi porzioni di umanità. però per farlo occorrono conoscenza, intelligenza e controllo dei diretti interessati.**
<!-- controllare in word era evidenziato azzurro -->

È in questo contesto che assumono sempre maggiore rilevanza i concetti di accessibilità e usabilità. 
Trattato istitutivo della comunità europea [direttiva-europea-pdf] art.13 
> Fatte salve le altre disposizioni del presente trattato e nell’ambito delle competenze da esso conferite alla Comunità, il Consiglio, deliberando all’unanimità su proposta della Commissione e previa consultazione del Parlamento europeo, può prendere i provvedimenti opportuni per combattere le discriminazioni fondate sul sesso, la razza o l’origine etnica, la religione o le convinzioni personali, gli handicap, l’età o le tendenze sessuali.

Cui segue la direttiva (di chi?)
<!-- Cui segue la direttiva (di chi?) -->

La Legge 9 gennaio 2004, n. 4; “Disposizioni per favorire l’accesso dei soggetti disabili agli strumenti informatici” pubblicata sulla “Gazzetta Ufficiale” n. 13 del 17 gennaio 2004 definisce:
> Accessibilità…la capacità dei sistemi informatici, nelle forme e nei limiti consentiti dalle conoscenze tecnologiche, di erogare servizi e fornire informazioni fruibili, senza discriminazione, anche da parte di coloro che a causa di disabilità necessitano di tecnologie assistive o configurazioni particolari.

Questo si può attuare tramite “tecnologie assistive gli strumenti e le soluzioni tecniche, hardware e software, che permettono alla persona disabile, superando o riducendo le condizioni di svantaggio, di accedere alle informazioni e ai servizi erogati dai sistemi informatici”
Si parla di accessibilità dei sistemi informatici quando ci si riferisce alla possibilità di fruire delle informazioni e dei servizi forniti, attraverso sistemi hardware e software appositamente progettati.

Al concetto di accessibilità si connette quello di usabilità, definita dalle norme standard ISO9241-210:2010:
<!-- verificare la citazione perché questa si sovrappone a quella di accessibilità non specifica adeguatamente il concetto di usabilità -->
> ”Il grado in cui un prodotto può essere usato da particolari utenti per raggiungere certi obiettivi con efficacia, efficienza, soddisfazione, in uno specifico contesto d’uso.”

La norma si prodiga ulteriormente nell’esplicitare i termini:
- Efficacia: intesa come precisione e completezza del raggiungimento di obiettivi prefissati da parte degli utenti.
- Efficienza: si intende in rapporto tra le risorse impiegate in relazione all’efficacia definita in precedenza.
- Soddisfazione: grado di facilità con cui gli utenti ottengono gli obiettivi tramite l’uso del prodotto.
L’usabilità quindi si propone l’intento di ridurre la fatica dell’utente nell’utilizzo di prodotti, facendo in modo che siano facili da comprendere, da usare, da ricordare e apprendere e che rendano possibile il recupero di eventuali errori.
E’ opportuno sottolineare la fondamentale differenza tra i due concetti: se l’usabilità è la ricerca di una semplificazione che si rivolge a tutti gli utenti, l’accessibilità cerca di sopperire alle carenze dovute a specifiche disabilità con tecnologie dedicate.

## 2.3 decreti
Il concetto di usabilità nasce negli anni ’60 ma si è poi sviluppato alla fine degli anni ’80 con il diffondersi delle tecnologie informatiche e del personal computer tra un numero sempre crescente di soggetti: fino ad allora il problema non sussisteva, in quanto queste tecnologie erano utilizzate esclusivamente da esperti. 
**La crescita del web in ambito sociale ha comportato la necessità di rendere accessibili i siti e le sue stesse risorse e informazioni. Questo ha portato gli enti governativi a muoversi da un punto di vista legislativo, arrivando a promuovere delle linee guida specifiche per il web che sono state ritenute a tal punto valide dagli esperti del settore, da essere applicate per l’accessibilità anche nell’ambito dello sviluppo software, che invece non è stato coperto da alcuna specifica normativa. Stesso discorso si può applicare allo sviluppo di applicazioni mobile, la cui accessibilità non viene richiesta al momento dell’inserimento sulle piattaforme store, ma è a totale discrezione dello sviluppatore. Di prospettiva, visto il prorompente sviluppo delle applicazioni mobile negli ultimi anni, ci si aspetta che gli enti normativi a breve intervengano anche in questo ambito. **
<!-- in word evidenziato in azzurro -->

## 2.4 attuazione nello sviluppo software e web
<!-- da fare -->

## 2.5 Assistive technologyes definizione
<!-- in word evidenziato in giallo -->

Con il termine “assistive technologies” (AT), o nella traduzione italiana “tecnologie assistive”, ci si riferisce all’insieme delle soluzioni hardware e software che rendono accessibile e usabile qualsiasi sistema informatico da parte di persone con disabilità fisica, sensoriale o cognitiva, consentendo la fruizione delle informazioni e dei servizi da esso erogati.
L’ideale sarebbe progettare programmi e applicazioni nativamente accessibili, ma troppo spesso questi principi rimangono solo delle enunciazioni.
Le HMI (Human Machine Interfaces), ossia interfacce uomo macchina, sono l’insieme delle parti hardware e software che forniscono informazioni relative allo stato della macchina e ai comandi necessari all’utente per svolgere le funzioni specifiche per cui il programma è stato progettato. [^massimiliano-salfi-assistive-technology-slide]
[^massimiliano-salfi-AT]

La prima formalizzazione del concetto di assistive technology si trova nel “Technology-Related Assistance for Individuals with Disabilities Act” [^the-tech-act] 1988 “The Tech Act” nel 1988, aggiornato nel 1994 e infine, quattro anni più tardi, sostituito dall’”Assistive Technology Act” "AT Act".
Negli “Access Board's [^electronic-and-Information Technology-Accessibility-Standards]
si trova la medesima definizione di accessibilità, importante per questo lavoro, in quanto sviluppata come richiesto dall’emendamento del 1998 alla **sezione 508 del Rehabilitation Act, più volte citato.**
<!-- in word evidenziato in giallo -->

## 2.6 Esempi di assistive technologies legati alla disabilità visiva
Fin dalla nascita del personal computer le aziende produttrici si sono interrogate sulle modalità di fruizione di tale strumento tramite mezzi alternativi allo schermo [^germano-carella-ausili-screenreader-1]
A supporto della disabilità visiva, le tecniche applicate prevedevano principalmente l’utilizzo di capacità sensoriali alternative, quindi l’udito e il tatto. Nasce da qui l’idea di usufruire della tecnologia dei sintetizzatori vocali, software in grado di riprodurre fonemi legati in sillabe che, opportunamente combinati, erano in grado di trasmettere frasi di senso compiuto e la produzione di lettori in grado di riprodurre scritte braille tramite materiali piezoelettrici, aggiornabili con impulsi elettronici ed usufruibili tramite tatto. Solo successivamente si sono 
sviluppati software di input tramite comando vocale. 
 

<!-- INSERIRE TABELLE CON ESEMPI TECNOLOGIE ASSISTIVE E RELATIVO LINK https://www.agid.gov.it/sites/default/files/repository_files/documentazione/agid_specifiche_tecniche_in_consultazione.pdf 
(…… ; consultato 25 novembre 2018). -->

### 2.6.1 Screen Reader
Con il termine *screen reader* si intende una categoria di ausili composta da software in grado di analizzare, filtrare, interpretare il contenuto del display di un dispositivo informatico e riprodurlo come output in formato audio, attraverso la funzione di text to speech [^text-to-speach], con sintesi vocale o display braille [^display-braille] (si veda capitolo dedicato 2.6.2 Barra Braille). Alla loro nascita questi software dovevano essere installati appositamente suuicomputer che il cieco avrebbe utilizzato, mentre successivamente sono diventati esportabili tramite chiavete usb o hard-disk essterni e in tempi anccor più recenti sono le case produttrici, Windows, Macc..., che li inseriscono di default, oggi un non vedente può usare qualsiasi dispositivo.  

https://cs.stanford.edu/people/eroberts/courses/soco/projects/2005-06/accessibility/software.html
<!-- citare le sue fonti bibliografiche a fondo pagina del sito -->

Il sistema di screen reader è composto da due parti: una detta front-end e una di Back-end. Le due funzioni del front-end sono: la normalizzazione, ovvero un'analisi del testo che converta sigle, abbreviazioni, numeri in parole, e l'analisi linguistica, che traspone gli idiomi in fonemi facendone un'analisi linguistica in grado di creare intonazione, pause, respiri, periodi. 
La funzionalità che si occupa di riprodurre in suoni il contenuto testuale, analizzato e opportunamente filtrato dallo screen reader, è il baack-end ed è chiamata sintesi vocale, in quanto in grado di articolare suoni sintetizzati, quindi artificiali, in fonemi [^fonemi] Il sintetizzatore per funzionare sfrutta la scheda audio del computer: questo, come verrà esposto in seguito, comporterà dei problemi di compatibilità con i software di editing musicale.


<!-- wikipedia: cambiare fonte per omografi e numeri -->

Le regole grammaticali della lingua consentono di ottenere una corretta pronuncia dei vocaboli e persino le parole abbreviate; possono invece creare problemi: i nomi composti, i termini con successioni di lettere inusuali, le omografie e numeri [^omografi-numeri]. Con i progressivi miglioramenti delle tecnologie alla base delle sintesi vocali, tali problematiche stanno diminuendo 
I primi sintetizzatori ricreavano voci dal suono metallico e spesso la lettura risultava difficoltosa o addirittura incomprensibile, con evidenti riflessi negativi sull’efficacia del messaggio da parte dell’utilizzatore. Fortunatamente questa tecnologia, che ha avuto un ampio sviluppo avendo trovato riscontro in applicazioni commerciali, è stata continuamente migliorata negli anni, soprattutto dal punto di vista della naturalezza della lettura e dell’intelligibilità. Questo ha prodotto voci ormai molto simili a quelle umane, in grado di riprodurre suoni non solo comprensibili, ma che riflettano anche le intonazioni del parlato, come nel fondamentale caso delle frasi esclamative o interrogative. Notevoli progressi si riscontrano anche relativamente alla normalizzazione del testo.
Per contro sintesi molto elaborate e con voci simili alla dizione umana richiedono un utilizzo di memoria del computer molto ingenti, tali da rallentare l'esecuzione di operazioni anche elementari; questo è il motivo per cui si trovano in commercio sintesi con voci meno gradevoli che caricano meno la CPU facilitando le operazioni da svolgere. Voci molto elaborate vengono utilizzate di preferenza da enti e società che dispongono di grandi elaboratori, piuttosto che dal singolo utente per le moivazioni di sovraccarico del PC esposte sopra.

Esistono varie modalità d’uso di una sintesi vocale, vi sono diverse modalità di navigazione degli elementi e comandi per la lettura di un testo, che può essere navigato per caratteri, parole, righe
[^mallard-youtube]
è possibile inoltre trovare una stringa di testo nella videata; annunciare la locazione del cursore o dell’elemento selezionato. 
Esistono anche funzioni più avanzate, come: leggere la porzione di testo con una particolare formattazione; leggere una predeterminata porzione dello schermo a richiesta; leggere la porzione di testo selezionata, permette all’utente di conoscere qual è la scelta attiva in un menù. [^funzionamento-screenreader-american-foundation]
Per eseguire tali operazioni i comandi differiscono secondo la versione del sistema operativo impiegato, nonché quella dello screen reader, cosa che crea non poco disagio all’utente. Esistono però anche comandi che attivano la funzionalità di suggerimento delle shortcut relative allo screen reader.
Molti sistemi operativi supportano screen reader ad essi dedicati: Linux utilizza Orca, Windows Vista, Windows XP, Windows 98, Windows ME e Windows NT supportano Narrator; infine Apple Macintosh computers il sistema OS X con lo screen reader VoiceOve [^tipologie-screenreader-american-foundation]
Dall’inizio degli anni ’90 la conformazione dei sistemi operativi non è più, per l’utente, di natura testuale, ma si basa sulla componente grafica della GUI (Graphical User Interface), che è composta da icone e pulsanti. Ne consegue che lo screen reader non può più esclusivamente estrarre le informazioni di natura testuale presenti nella videata, ma deve essere in grado di leggere anche le componenti grafiche, mediante opportuni accorgimenti e appositi metadati, testi alternativi, tag.
Di seguito vengono elencate le principali funzioni dello screen reader.
- Identificare e leggere testi. Normalmente ciò che è rappresentato a schermo, viene realizzato tramite indicazioni di coordinate di pixel, secondo una matrice che indica quali sono i colorati e quali no. Lo screen reader non è in grado di distinguere l’elemento testuale da quello grafico, pertanto intercetta l’input di testo prima che venga immesso e lo immagazzina in un’altra matrice chiamata OMS (Off-Screen Model), basandosi nel suo funzionamento esclusivamente su questa e ignorando la prima.
- Annunciare e identificare le funzioni di Windows construct. Windows mantiene il tipo o la classe di ciascun elemento in un’applicazione e la maggior parte degli screen reader è in grado di recuperare questa informazione e renderla disponibile all’utente. Per esempio, in una finestra di dialogo sono normalmente in grado di dire all’utente quali siano i pulsanti e quali gli items.
- Identificazione degli elementi grafici. Alcune funzionalità delle finestre non sono etichettate con testo, ma semplicemente riportate come icone o immagini. Lo screen reader è in grado di etichettare questi elementi grafici in modo che possano avere significato per l’utente. (Questo argomento verrà esplicitato più dettagliatamente nel paragrafo riguardante le APIs).
- Fornire un’interfaccia alternativa efficiente. Scopo ultimo dello screen reader è rendere possibile l’utilizzo del computer da parte di chi non è in condizione di leggere lo schermo, tramite accorgimenti che permettano la fruizione delle informazioni in esso contenute. Per questo motivo è necessario introdurre comandi opportunamente semplificati che consentano di selezionare le informazioni o le parti di schermo richiesti in uno specifico momento, per una determinata operazione, permettendo di lavorare in autonomia e senza eccessive perdite di tempo. Esistono ad esempio comandi che consentono di far leggere alla sintesi l’intero contenuto dello schermo dall’angolo in alto a sinistra, fino all’angolo in basso a destra, oppure di portare direttamente il cursore al punto d’interesse, saltando le parti intermedie. Vi sono altresì comandi per leggere secondo parametri scelti dall’utente: lettura per intestazioni di pagina, link, colonne, righe.
- Funzionalità di mouse o puntatore. Una evidente difficoltà nell’utilizzo del mouse, soprattutto per i non vedenti totali, è legata al posizionamento del puntatore. Tale problematica è stata risolta suddividendo lo schermo in righe e colonne, nelle quali è possibile muovere il puntatore di unità, sfruttando i movimenti delle frecce della tastiera, e emularne il click usando il tastierino numerico. 
L’argomento legato alle tre tipologie di focus tra sintesi, tastiera e mouse e come esse interagiscano tra loro, verrà trattata più avanti.
<!-- SPIEGARE FOCUS E TROVARE DOVE METTERLO, SICURAMENTE NON QUI -->

#### PARLARE DI API’s
Lo screen reader per interfacciarsi con la barra braille si appoggia alle APIs standard del sistema operativo per fornire allo screen reader le informazioni di accessibilità, ad esempio le Users Interface Automation (UIA), abbreviate come UI automation di windows. Esse forniscono allo screen reader, e di conseguenza alla barrabraille, informazioni riguardo l’azione da parte dell’utente (l’elemento è selezionato, il pulsante è stato premuto, il menù è stato espanso ecc…); sul tipo di controllo (pulsante, menù a discesa, checkbox, slider, link), 
**proprietà del controllo (nome), automation properties (comandi da tastiera),**
<!-- inserire elementi mancanti -->

patterns/behaviour (toggle, invoke, select, expande/collapse); infine “layout the hierarky for expected behaviour”.  (tratto da PDF "UIA Windows Accessibility" dal sito Microsoft)[^layout-the-hierarky-for-expected-behaviour-pdf-sito-microsoft]

da questo link si può eseguire il suo download) 
Le UIA danno anche informazioni sul contesto in cui il comando si trova; il contesto in cui il focus è posizionato (ad esempio il cursore di testo all’apertura di un documento di Word)
La quantità di informaziooni fornite all’utente dipende da come quest’ultimo ha impostato il “grado di verbosità”, ad esempio si può scegliere se lo screen reader annuncia o meno che il pulsante è selezionato, se dà suggerimenti sulle azioni che è possibile eseguire (premere invio o spazio per selezionare); oppure ancora (premere le frecce) per espandere il sottomenù quindi si può anche impostare che vengano forniti suggerimenti sulle shortcut da utilizzare. (Si noti che molto spesso è data la possibilità di personalizzare le shortcut, sia relative a alcune funzioni interne allo screen reader, sia relative a funzionalità presenti nei vari programmi, ma non si affronterà questo argomento in quanto il tentativo è di riuscire a essere il più generici possibile).
NB si ricorda che anche il mignifier fa uso delle UIA ad esempio per captare quando il focus, mosso dai comandi da tastiera o dal mouse, viene spostato dall’utente.

**C’è CONTRADDIZIONE NEL VIDEO DELLA MICROSOFT: PRIMA SUDDIVIDE SHORTCUT NELLE AUTOMATION PROPERTIES DA NOME DEL CONTROLLO CHE è INSERITO NELLE PROPERTIES, POI, NELLE 2 VOLTE SUCCESSIVE CHE RICOMPARE L’ARGOMENTO, NAME E SHORTCUT VENGONO ENTRAMBE MESSE SOTTO LA VOCE PROPERTIES.**
<!-- in word evidenziato in azzurro -->

**Active Accessibility
Microsoft Active Accessibility (MSAA) is a set of programming language enhancements and standards for programmers to follow. For a user to benefit from MSAA, it is necessary for it to be incorporated into both the application and the screen reader being used. Applications that use MSAA currently include: Microsoft Word, Excel, Internet Explorer, and Lotus Notes.**
<!-- in word evidenziato in giallo - tradurre e rielaborare -->
## 2.6.2 Barra Braille
![](.\images\generic\barra-braille.jpg)
[^immagine-barra-braille]: tratto da collezione privata
Il testo “Assistive Technology for Visually Impaired and Blind People” definisce: *“Refreshable Braille displays or soft Braille displays are output devices for reading text from a computer screen or ﬁle in Braille cells”.* [^barra-braille-definizione]
In italiano questo supporto viene tradotto con il termine “barra braille”; si tratta di un dispositivo elettromeccanico in grado di riprodurre caratteri alfanumerici in formato braille, sollevando alternativamente dei pin plastici, tramite materiale piezoelettrico (Figura 1).
Generalmente è composto da una striscia di matrici, a ciascuna delle quali corrisponde un singolo carattere braille: il numero delle matrici è caratteristica determinante la capacità e la velocità di lettura. All’esaurimento del numero di matrici, tramite appositi tasti, l’utente può aggiornare i caratteri rappresentati per proseguire la lettura. 
Il braille display può funzionare esclusivamente appoggiandosi ad un software di screen reader, in quanto il testo da riprodurre deve prima essere filtrato e tradotto in segnali elettronici corretti, per poter riprodurre adeguatamente i caratteri braille. 
L’utente può così scegliere di utilizzare sia l’output braille che l’output sonoro tramite sintesi voc, oppure in alternanza secondo necessità. 
Questo supporto consente all’utente di essere il protagonista della lettura, anziché ascoltatore passivo, con notevoli benefici per l’apprendimento. Questi dispositivi sono pensati per essere portatili, ma il loro uso è comunque limitato del fatto che devono essere sempre supportati dal software di screen reader apposito, risultando quindi utilizzabile esclusivamente solamente sul PC dell’utente appositamente settato e non può invece essere interfacciato con altri supporti hardware privi del software. Un altro aspetto da non sottovalutare è la velocità di aggiornamento e spostamento dei pin da parte dell’apparecchio, che ha notevole influenza sulla velocità di lettura, soprattutto in dispositivi dotati di uno scarso numero di matrici.
Sono già disponibili sul mercato display braille dotati di memoria interna e di tastiera braille di input che quindi posso servire da supporto I/O (input & output), unendo in un solo dispositivo le due funzioni.  

NELLE FONTI CONSULTATE CITARE ANCHE 
[^barra-braille-manuale-papenmeier]

[^UIA-microsoft-youtube]

[^sito-microsoft-ufficiale]

### 2.6.3 Speech Recognition
Si definisce Speech Recognition la capacità di un supporto elettronico di comprendere il parlato umano e di eseguire operazioni a seguito di quanto recepito. Tale sistema necessita di un microfono che capti la voce del parlante e di un hardware che converta il segnale da onde analogiche a segnale digitale. Successivamente i dati in formato digitale sono processati da un software dedicato che è in grado di interpretare i fonemi individuando le singole parole e convertirle poi in formato macchina, in modo tale che possano essere finalmente utilizzate dal supporto. Questo sistema, sfrutta algoritmi di modellazione acustica che individuano la relazione tra le parole e il segnale audio, in seguito tale processo viene affinato utilizzando una modellazione linguistica in grado di riconoscere i significati di parole simili all’interno del contesto di una frase, in modo da non creare ambiguità di significato e di comandi.
Le prime release di questo genere di software avevano un vocabolario molto limitato e potevano interpretare solo semplici frasi che fossero ben scandite e perfettamente pronunciate. 
I due più famosi software erano Via Voice [^via-voice] a metà degli anni ’90 e Dragon Naturally Speaking [^dragon-Naturally-Speaking] dell'IBM del 1975, la cui più recente versione risale al settembre 2016.
Attualmente queste funzioni hanno riscontrato un notevole utilizzo commerciale, soprattutto nell’era degli smartphone, supportano l’utilizzo alla guida o hands free e recentemente in dispositivi come il Google Home supportando l’IOT.
<!-- AMPLIARE IOT -->

Uno degli utilizzi più comuni sono software di dettatura cosiddetti “speech to text” che si limitano a interpretare quanto detto e trascriverlo su un documento di un programma di elaborazione di testi. Questi ultimi non sono però in grado di eseguire comandi. Un software molto conosciuto è Dragon Naturally Speaking; [^dragon-Naturally-Speaking] oppure recenti funzionalità built-in nei sistemi operativi Windows e Machintosh.
Alcuni programmi supportano in automatico lo speech recognition mentre altri no, ma è una funzione che può essere abili	tata per ogni applicazione selezionando “all programs” > “Accessories” > “ease of access” > “windows speech recognition” > “enable dictation everywhere”.
In OSX “preferences pannel” > “dictation and speech”.
La nuova frontiera di sviluppo di queste tecnologie sono l’interactive speech e l’utilizzo hands free di dispositivi mobile. Tutta questa branca ha 

Deep learning e machine learning
I più famosi interactive speech si sono sviluppati come “assistenti” i più famosi sono Cortana di Windows e Siri di OSX.
Tradotto da me prendendo dal sito: https://searchcrm.techtarget.com/definition/speech-recognition (aggiornato 10 gennaio 2014; consultato 26 novembre 2018)

voice recognition permette agli utenti di comandare il device dando comandi vocali già stando a dei dettami dell'articolo del 2005 "CIT stanford" l'accuratezza di comprensione dei vocal regognition dell'input a questi programmi era superiore al 90% ed erano in grado di apprendere, attraverso l'utilizzo da parte dell'utente, la modalità d'uso e arrivare a una comprensione sempre maggiore.
<!-- QUALE  TECNOLOGIA PERMETTEVA A PRG DI IMPARARE? -->

“Il deep learning è un caso particolare di machine learning, e le reti neurali sono i sistemi di calcolo (con le loro architetture, talvolta non del tipo Von Neumann-Zuse) sui quali essi sono implementati ed operano algoritmicamente.”

### 2.6.4 Screen Magnifier
E' un software in gardo di presentare l'output a schermo ingrandendolo. si può ingrandire una parte o lo schermo intero.
è impiegato soltatno da chi è in possesso di residuo visivo minimo o ipovedenti. chi ha un residuo visivo eccessivamente ridotto o completamente compromesso non può far uso di questo assistive technology ma solo di screenr eader e barrabraille.
la porzione di schermo ingrandita, detta focus, deve poter coprire lo schermo parzialmente o interamente, essa deve includere il contenuto d'interesse per l'utente e il puntatore o cursore debitamente ingrandito. questa porzione deve poter essere dall'utente allargata o ristretta a piacimento e deve essere in grado di seguire i movimenti del puntatore ingrandendo la nuova area di interesse indicata da nuovo puntamento del mouse o tramite shorcut; segue i n maniera automatica i cambiamenti di stato degli elementi o dei pop-up e pop-down.
Apple mette a disposizione un’ulteriore funzionalità, chiamata “cursor magnification” [^cursor-magnification]  che consente di ingrandire maggiormente il puntatore, se le possibilità offerte di default non sono sufficienti. Questa opzione però si disattiva nel caso in cui l’utente spenga o riavvii il computer, esegua il logout dal proprio account.
color invertion inversione cromatica spesso i disabili visivi preferiscono leggere invertendo i colori, tipicamente portando il testo da nero su bianco a bianco / giallo su fondo blu/nero.
questo può ridurre la luminescenza ed è utile soprattuto per degenrazione della macula in età avanzata.
smoothing il compensa la sgranatura dell'immagine dovuta all'ingrandimento eccessivo, fornendo un'interpolazione.
cursor costumization personalizzazione dei cursori in modo di facilitarne l'identificazione a schermo ingrandendoli, scurendoli con varie gradazioni di colori che diano contrasto sullo sfondo.
differenti modalità di ingrandimento la modalità di ingrandimetno può essere customizzabile impostando una zona di ingrandimento fissa; una lente da spostare all'interno dello schermo; oppure l'intero schermo ingrandito.
Alcuni magnifier hanno integrati degli screen reader basilari che leggono la porzione di schermo ingrandita (leggeri a livello di software occupano poca memoria).
esempi di magnifier:
windows a partire dal 1998 ha integrato un applicativo di ingrandimento chiamato Magnifier.
Tale funzione è tutt’ora disponibile, in Windows 10 per attivarlo è sufficiente richiamare la funzione dal menù Start oppure aprire il pannello “impostazioni” e mettere il flag su “lente di ingrandimento”. Dal medesimo pannello è poi possibile operare ulteriori aggiustamenti. (Si è scelto di riportare solamente la procedura relativa a Windows 10, escludendo le precedenti versioni, in quanto è il sistema operativo su cui sono stati eseguiti i test).
OSX IOS si attiva con specifici imput (shortcut, mouse pad, scrool)
La procedura standard in un computer Mac è aprire Apple menu e selezionare System Preferences.
All’interno del System row selezionare Universal Access, attivare il pulsante Zoom. Mentre per ulteriori opzioni raggiungere il pulsante Options.
(La medesima scelta di esporre solo le procedure relative alla versione del sistema operativo impiegato per eseguire i test sui programmi, per identiche ragioni, è stata operata anche in merito all’analisi procedurale di attivazione dello zoom nel sistema operativo Mac, le cui operazioni peraltro non variano di molto tra una versione e l’altra).
La procedura innanzi esposta riguarda la versione Mac Mojave 10.14.


NELLE FONTI CITARE A CHE 
cita da wikipedia le reference:
sito IOS OSX: 
https://support.apple.com/en-us/HT204390 SHORTCUT SOLO PER IPHONE IPAD
Magnifier in sito ufficiale Apple, su computer, ipad, iphone https://www.lifewire.com/zoom-apples-built-in-screen-magnifier-198673 
sito microsoft: https://support.microsoft.com/it-it/help/4052291/accessories-how-do-i-turn-my-mouse-magnifier-on-and-off 
(aggiornato 10 aprile 2018; consultato 13 novembre 2018)
[guida all’uso e risoluzione di problemi della Microsoft, trovaa in calce alla pagina wikipedia]
wikipedia: https://en.m.wikipedia.org/wiki/Screen_magnifier

### 2.7 Storia accessibilità:/ tipologie screenreaader a partire dagli anni 90
Storicamente, i primi applicativi sviluppati si occupavano esclusivamente di riprodurre testi, in quanto si riteneva che l’utenza di non vedenti potesse servirsi del PC ad esclusivo scopo di lettura, e non invece di altri applicativi quali fogli di calcolo oppure linguaggi di programmazione. 
Quando ci si rese conto che invece lo sviluppo di software più complessi avrebbe aperto notevoli opportunità, entrarono in commercio numerosi software proprietari, tra cui il più famoso per diffusione fu JAWS (acronimo di *Job Access With Speech).* Utilizzabile esclusivamente su sistema operativo Windows 98 o successivo, aveva come caratteristica unica la possibilità di utilizzare i menu a cascata e il poter sviluppare delle macro di personalizzazione del suo utilizzo pur non andando a modificare la normale interfaccia utente. Questo ne comportò una notevole diffusione perché nonostante i costi elevati, in Italia spesso finanziati dal sistema sanitario locale o dal sistema scolastico, la suite di comandi da tastiera particolarmente complicata. È possibile rintracciare differenti pagine web e letteratura specifica in merito in cui si spiega come utiliizzare JAWS e vi si possono trovare comandi completamente differenti per assolvere alla medesima funzione, questo anche a causa della possibilità di personalizzazione degli stessi. Oltretutto, gli stessi comandi che avrebbero dovuto essere facilmente accessibili, risultavano di complicato utilizzo, in quanto prevedono l’utilizzo dei tasti “Home” ed “Insert”, che non sono ergonomici per un'utenza non vedente.
Un altro elemento sfavorevole, è legato all’utilizzo del browser, in quanto molte delle shortcut necessarie a questo scopo vengono interpretate dal software come comandi e non come oggetto della ricerca. [^germano-carella-ausili-screenreader-2]
Recentemente, anche grazie alla spinta normativa imposta dai vari goversni, hanno cominciato a diffondersi software efficienti e gratuiti, che hanno comportato una notevole svolta nell’autonomia dei disabili visivi. 
Sicuramente degno di nota è il software opensource gratuito NVDA *(Non Visual Desktop Access)*, introdotto a partire dalla versione Windows7 e disponibile anche in versione “portable” ovvero installabile su supporto esterno al PC e quindi trasportabile facilemente da un PC ad un altro, rendendo immediatamente accessibile la macchina di interesse. Questo fatto ha abbattuto un’ulteriore barriera, secondo cui il disabile visvo fosse costretto ad utilizzare esclusivamente i propri supporti hardware. 

** Un altro aspetto da non sottovalutare, in aggiunta a quello tecnico di usabilità delle informazioni, è legato alla qualità della riproduzione del suono e della voce. 

Successivamente, sono stati sviluppati software opensource o comunque gratuiti 
l'utente tenta di eeseguire una ricerca in un browser, vengono interpretate molti tasti digitati vengono intrepretati dallo screen reader come sue proprie shortcut (per ovviaer a questo sconveniente gli sviluppatori hano diviso le tipologie di navigazione in due: modalità maschere (per dare comandi allo jaws e modalità d'inserimentos semplice per poter eseguire la ricerca in  modo comune)

. registrazione iphone scarfia differenza tra assistente vocale e screen reader
**
<!-- in word evidenziato in giallo -->

IBM ha , prima ditta interessarsi di accessiblità svilupando un suo screrenreader per i dipendenti interni (v "concetto di accessibilità.doc") ha implementato uno screenr eader denominato Home Page Reader sviluppato specificatamente solo per poche applicazioni come wordpad, windows desktop, notepad.
Narrator, sempre per windows 8 e successive, è considerato leggermente migliore rispeto agli in quanto meno complesso, tutavia presentava difficoltà al primo utilizzo
perchè non trovavi elenco dei comandi e ingenerale perchè le short cut prevedevano l'impiego dell'home key, di complesso utilizzo come già detto.

<!-- CITARE SITO MICROSOFT.COM -->

VoiceOver per Mac è meglio strutturato dei precedenti elencati, all'avvio del sistema operativo l'utente non vedente può facilmente accedere al tutorial  direttamente, per imparare a usarlo.
presenta un numero minore di comandi rapidi rispetto a JAWS, comandi che prevedono il tasto chiave Home/V.O oppure capslock o insert

### 2.7.1 / Storia tecniche accessibilità
<!-- da completare -->

### 2.7.2 / riflessione su come può essere reso accessibile software audio [in generale (sintesi vocale, controller esterni] – sezione che si approfondirà nella seconda sezione della tesi (180 pag)


## Conclusioni accessiblità
Ciò che ha portato a uno spinto sviluppo negli ultimi dieci anni degli screen reader e del vocal recognition delle tecnologie di accesibilità è stao il fatto che hanno troavato vasto utilizzo anche dai
normo dotati che possono così far cose che altrimenti non potrebbero fare per esempio i comandi vocali mentre guidi l'auto, ottenere rispota al telefono a distanza /google home); il device riconosce la specifica voce ("ok google").
tutto ciò ha avuto ricaduta fondamentale sull'uso dei device da parte dei disabili che altrimenti non avrebbero mai ricevuto mai una ricerca così spinta.
legge spinge a fare il minimo indispensabile per soddisfare i requisiti di leggi, la ricaduta economica va oltre.

